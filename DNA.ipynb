{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfsC9xnYWl-h"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "!pip install catboost \n",
        "!pip install tensorflow-addons==0.15.0\n",
        "\n",
        "# !pip install pycaret[full]\n",
        "# from pycaret.utils import enable_colab\n",
        "# from pycaret.classification import *\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn.decomposition\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import StratifiedKFold , KFold\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers \n",
        "import tensorflow_addons.metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/gdrive/My Drive/Colab Notebooks/dacon/dna_classify\"\n",
        "data_folder = f\"{path}/data\"\n",
        "\n",
        "train = pd.read_csv(f\"{data_folder}/train.csv\")\n",
        "test = pd.read_csv(f\"{data_folder}/test.csv\")\n",
        "sample_submission = pd.read_csv(f\"{data_folder}/sample_submission.csv\")\n",
        "\n",
        "display(train,test)"
      ],
      "metadata": {
        "id": "PBemMfXQXbKr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "outputId": "d7879a70-29ed-47b7-cfb6-9f1aacca0ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            id  father  mother  gender  trait SNP_01 SNP_02 SNP_03 SNP_04  \\\n",
              "0    TRAIN_000       0       0       0      2    G G    A G    A A    G A   \n",
              "1    TRAIN_001       0       0       0      2    A G    A G    C A    A A   \n",
              "2    TRAIN_002       0       0       0      2    G G    G G    A A    G A   \n",
              "3    TRAIN_003       0       0       0      1    A A    G G    A A    G A   \n",
              "4    TRAIN_004       0       0       0      2    G G    G G    C C    A A   \n",
              "..         ...     ...     ...     ...    ...    ...    ...    ...    ...   \n",
              "257  TRAIN_257       0       0       0      2    A G    A G    A A    G A   \n",
              "258  TRAIN_258       0       0       0      2    G G    A A    C A    A A   \n",
              "259  TRAIN_259       0       0       0      1    A G    G G    A A    G A   \n",
              "260  TRAIN_260       0       0       0      1    A A    G G    A A    G A   \n",
              "261  TRAIN_261       0       0       0      2    G G    A G    C A    G G   \n",
              "\n",
              "    SNP_05  ... SNP_07 SNP_08 SNP_09 SNP_10 SNP_11 SNP_12 SNP_13 SNP_14  \\\n",
              "0      C A  ...    A A    G G    A A    G G    A G    A A    A A    A A   \n",
              "1      A A  ...    A A    G A    A A    A G    A A    G A    G G    A A   \n",
              "2      C C  ...    A A    G A    G A    A G    A A    A A    A A    A A   \n",
              "3      A A  ...    G G    A A    G G    A G    G G    G G    G G    A A   \n",
              "4      C C  ...    A A    A A    A A    G G    A A    A A    A G    A A   \n",
              "..     ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "257    C C  ...    A A    G A    A A    G G    A G    G A    A A    A A   \n",
              "258    A A  ...    G A    G A    A A    A G    A G    A A    A G    A A   \n",
              "259    A A  ...    G G    G A    G A    A A    G G    G G    G G    C A   \n",
              "260    A A  ...    G G    A A    G A    A G    A G    G A    G G    C A   \n",
              "261    C C  ...    A A    A A    A A    G G    A A    A A    G G    A A   \n",
              "\n",
              "    SNP_15 class  \n",
              "0      A A     B  \n",
              "1      A A     C  \n",
              "2      A A     B  \n",
              "3      G G     A  \n",
              "4      G A     C  \n",
              "..     ...   ...  \n",
              "257    A A     B  \n",
              "258    G A     C  \n",
              "259    G G     A  \n",
              "260    G G     A  \n",
              "261    G A     B  \n",
              "\n",
              "[262 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1329a0f1-cada-4864-a88a-c2f436649ebc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>father</th>\n",
              "      <th>mother</th>\n",
              "      <th>gender</th>\n",
              "      <th>trait</th>\n",
              "      <th>SNP_01</th>\n",
              "      <th>SNP_02</th>\n",
              "      <th>SNP_03</th>\n",
              "      <th>SNP_04</th>\n",
              "      <th>SNP_05</th>\n",
              "      <th>...</th>\n",
              "      <th>SNP_07</th>\n",
              "      <th>SNP_08</th>\n",
              "      <th>SNP_09</th>\n",
              "      <th>SNP_10</th>\n",
              "      <th>SNP_11</th>\n",
              "      <th>SNP_12</th>\n",
              "      <th>SNP_13</th>\n",
              "      <th>SNP_14</th>\n",
              "      <th>SNP_15</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>C A</td>\n",
              "      <td>...</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRAIN_001</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>A G</td>\n",
              "      <td>A G</td>\n",
              "      <td>C A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>...</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TRAIN_002</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>C C</td>\n",
              "      <td>...</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRAIN_003</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>...</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TRAIN_004</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>C C</td>\n",
              "      <td>A A</td>\n",
              "      <td>C C</td>\n",
              "      <td>...</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>TRAIN_257</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>A G</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>C C</td>\n",
              "      <td>...</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>TRAIN_258</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>C A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>...</td>\n",
              "      <td>G A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>TRAIN_259</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A G</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>...</td>\n",
              "      <td>G G</td>\n",
              "      <td>G A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>C A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>TRAIN_260</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>...</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A G</td>\n",
              "      <td>G A</td>\n",
              "      <td>G G</td>\n",
              "      <td>C A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>TRAIN_261</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>C A</td>\n",
              "      <td>G G</td>\n",
              "      <td>C C</td>\n",
              "      <td>...</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>B</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>262 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1329a0f1-cada-4864-a88a-c2f436649ebc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1329a0f1-cada-4864-a88a-c2f436649ebc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1329a0f1-cada-4864-a88a-c2f436649ebc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           id  father  mother  gender  trait SNP_01 SNP_02 SNP_03 SNP_04  \\\n",
              "0    TEST_000       0       0       0      1    A G    G G    A A    G A   \n",
              "1    TEST_001       0       0       0      2    G G    A G    C C    G G   \n",
              "2    TEST_002       0       0       0      2    G G    A G    A A    A A   \n",
              "3    TEST_003       0       0       0      2    G G    A G    C A    A A   \n",
              "4    TEST_004       0       0       0      1    A A    G G    A A    G G   \n",
              "..        ...     ...     ...     ...    ...    ...    ...    ...    ...   \n",
              "170  TEST_170       0       0       0      2    A G    G G    C C    A A   \n",
              "171  TEST_171       0       0       0      2    G G    A A    A A    A A   \n",
              "172  TEST_172       0       0       0      2    G G    A A    A A    A A   \n",
              "173  TEST_173       0       0       0      2    A G    G G    C A    G A   \n",
              "174  TEST_174       0       0       0      2    G G    G G    C C    G A   \n",
              "\n",
              "    SNP_05 SNP_06 SNP_07 SNP_08 SNP_09 SNP_10 SNP_11 SNP_12 SNP_13 SNP_14  \\\n",
              "0      A A    A G    G G    G A    G A    A G    A G    G A    G G    C A   \n",
              "1      C C    A A    A A    A A    A A    G G    A G    A A    A A    A A   \n",
              "2      C A    A G    A A    A A    A A    A G    A A    G A    G G    A A   \n",
              "3      C C    A A    A A    A A    A A    G G    A A    G A    A G    A A   \n",
              "4      A A    G G    G G    A A    G G    A G    G G    G A    G G    A A   \n",
              "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "170    C A    A G    A A    G G    A A    G G    G G    A A    A A    A A   \n",
              "171    C A    A G    A A    A A    A A    A G    A A    A A    A G    A A   \n",
              "172    C A    A G    A A    A A    A A    G G    A G    A A    A G    A A   \n",
              "173    C C    G G    A A    G A    A A    G G    A G    A A    A A    A A   \n",
              "174    C A    A A    G A    G G    A A    G G    G G    A A    A A    A A   \n",
              "\n",
              "    SNP_15  \n",
              "0      G A  \n",
              "1      A A  \n",
              "2      G G  \n",
              "3      A A  \n",
              "4      G G  \n",
              "..     ...  \n",
              "170    G A  \n",
              "171    G A  \n",
              "172    G G  \n",
              "173    A A  \n",
              "174    A A  \n",
              "\n",
              "[175 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0393a61a-586f-40df-a1e7-596ec490fa04\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>father</th>\n",
              "      <th>mother</th>\n",
              "      <th>gender</th>\n",
              "      <th>trait</th>\n",
              "      <th>SNP_01</th>\n",
              "      <th>SNP_02</th>\n",
              "      <th>SNP_03</th>\n",
              "      <th>SNP_04</th>\n",
              "      <th>SNP_05</th>\n",
              "      <th>SNP_06</th>\n",
              "      <th>SNP_07</th>\n",
              "      <th>SNP_08</th>\n",
              "      <th>SNP_09</th>\n",
              "      <th>SNP_10</th>\n",
              "      <th>SNP_11</th>\n",
              "      <th>SNP_12</th>\n",
              "      <th>SNP_13</th>\n",
              "      <th>SNP_14</th>\n",
              "      <th>SNP_15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A G</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A G</td>\n",
              "      <td>G G</td>\n",
              "      <td>G A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A G</td>\n",
              "      <td>G A</td>\n",
              "      <td>G G</td>\n",
              "      <td>C A</td>\n",
              "      <td>G A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_001</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>C C</td>\n",
              "      <td>G G</td>\n",
              "      <td>C C</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_002</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>C A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_003</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>C A</td>\n",
              "      <td>A A</td>\n",
              "      <td>C C</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_004</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>G G</td>\n",
              "      <td>G A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>TEST_170</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>A G</td>\n",
              "      <td>G G</td>\n",
              "      <td>C C</td>\n",
              "      <td>A A</td>\n",
              "      <td>C A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>TEST_171</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>C A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>TEST_172</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>C A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>TEST_173</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>A G</td>\n",
              "      <td>G G</td>\n",
              "      <td>C A</td>\n",
              "      <td>G A</td>\n",
              "      <td>C C</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>TEST_174</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>C C</td>\n",
              "      <td>G A</td>\n",
              "      <td>C A</td>\n",
              "      <td>A A</td>\n",
              "      <td>G A</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>G G</td>\n",
              "      <td>G G</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "      <td>A A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>175 rows × 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0393a61a-586f-40df-a1e7-596ec490fa04')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0393a61a-586f-40df-a1e7-596ec490fa04 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0393a61a-586f-40df-a1e7-596ec490fa04');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in train:\n",
        "    print(\"----------\",col,\"----------\")\n",
        "    print(\"train\")\n",
        "    print(train[col].value_counts())\n",
        "    print(\"test\")\n",
        "    print(test[col].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YVs4bAxOvJPY",
        "outputId": "d7b74fdf-a40f-4206-d328-7f3fae50ef85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- id ----------\n",
            "train\n",
            "TRAIN_000    1\n",
            "TRAIN_164    1\n",
            "TRAIN_166    1\n",
            "TRAIN_167    1\n",
            "TRAIN_168    1\n",
            "            ..\n",
            "TRAIN_092    1\n",
            "TRAIN_093    1\n",
            "TRAIN_094    1\n",
            "TRAIN_095    1\n",
            "TRAIN_261    1\n",
            "Name: id, Length: 262, dtype: int64\n",
            "test\n",
            "TEST_000    1\n",
            "TEST_120    1\n",
            "TEST_112    1\n",
            "TEST_113    1\n",
            "TEST_114    1\n",
            "           ..\n",
            "TEST_060    1\n",
            "TEST_061    1\n",
            "TEST_062    1\n",
            "TEST_063    1\n",
            "TEST_174    1\n",
            "Name: id, Length: 175, dtype: int64\n",
            "---------- father ----------\n",
            "train\n",
            "0    262\n",
            "Name: father, dtype: int64\n",
            "test\n",
            "0    175\n",
            "Name: father, dtype: int64\n",
            "---------- mother ----------\n",
            "train\n",
            "0    262\n",
            "Name: mother, dtype: int64\n",
            "test\n",
            "0    175\n",
            "Name: mother, dtype: int64\n",
            "---------- gender ----------\n",
            "train\n",
            "0    262\n",
            "Name: gender, dtype: int64\n",
            "test\n",
            "0    175\n",
            "Name: gender, dtype: int64\n",
            "---------- trait ----------\n",
            "train\n",
            "2    193\n",
            "1     69\n",
            "Name: trait, dtype: int64\n",
            "test\n",
            "2    124\n",
            "1     51\n",
            "Name: trait, dtype: int64\n",
            "---------- SNP_01 ----------\n",
            "train\n",
            "G G    141\n",
            "A G     71\n",
            "A A     50\n",
            "Name: SNP_01, dtype: int64\n",
            "test\n",
            "G G    84\n",
            "A G    52\n",
            "A A    39\n",
            "Name: SNP_01, dtype: int64\n",
            "---------- SNP_02 ----------\n",
            "train\n",
            "G G    108\n",
            "A G     97\n",
            "A A     57\n",
            "Name: SNP_02, dtype: int64\n",
            "test\n",
            "G G    81\n",
            "A G    57\n",
            "A A    37\n",
            "Name: SNP_02, dtype: int64\n",
            "---------- SNP_03 ----------\n",
            "train\n",
            "A A    122\n",
            "C A     92\n",
            "C C     48\n",
            "Name: SNP_03, dtype: int64\n",
            "test\n",
            "A A    82\n",
            "C A    68\n",
            "C C    25\n",
            "Name: SNP_03, dtype: int64\n",
            "---------- SNP_04 ----------\n",
            "train\n",
            "A A    120\n",
            "G A     93\n",
            "G G     49\n",
            "Name: SNP_04, dtype: int64\n",
            "test\n",
            "G A    76\n",
            "A A    64\n",
            "G G    35\n",
            "Name: SNP_04, dtype: int64\n",
            "---------- SNP_05 ----------\n",
            "train\n",
            "A A    94\n",
            "C A    86\n",
            "C C    82\n",
            "Name: SNP_05, dtype: int64\n",
            "test\n",
            "C C    62\n",
            "C A    61\n",
            "A A    52\n",
            "Name: SNP_05, dtype: int64\n",
            "---------- SNP_06 ----------\n",
            "train\n",
            "A G    122\n",
            "G G     79\n",
            "A A     61\n",
            "Name: SNP_06, dtype: int64\n",
            "test\n",
            "A G    80\n",
            "A A    48\n",
            "G G    47\n",
            "Name: SNP_06, dtype: int64\n",
            "---------- SNP_07 ----------\n",
            "train\n",
            "A A    163\n",
            "G G     51\n",
            "G A     48\n",
            "Name: SNP_07, dtype: int64\n",
            "test\n",
            "A A    101\n",
            "G A     40\n",
            "G G     34\n",
            "Name: SNP_07, dtype: int64\n",
            "---------- SNP_08 ----------\n",
            "train\n",
            "G A    96\n",
            "A A    87\n",
            "G G    79\n",
            "Name: SNP_08, dtype: int64\n",
            "test\n",
            "A A    64\n",
            "G G    59\n",
            "G A    52\n",
            "Name: SNP_08, dtype: int64\n",
            "---------- SNP_09 ----------\n",
            "train\n",
            "A A    182\n",
            "G A     56\n",
            "G G     24\n",
            "Name: SNP_09, dtype: int64\n",
            "test\n",
            "A A    120\n",
            "G A     43\n",
            "G G     12\n",
            "Name: SNP_09, dtype: int64\n",
            "---------- SNP_10 ----------\n",
            "train\n",
            "G G    151\n",
            "A G     68\n",
            "A A     43\n",
            "Name: SNP_10, dtype: int64\n",
            "test\n",
            "G G    97\n",
            "A G    47\n",
            "A A    31\n",
            "Name: SNP_10, dtype: int64\n",
            "---------- SNP_11 ----------\n",
            "train\n",
            "A G    96\n",
            "A A    83\n",
            "G G    83\n",
            "Name: SNP_11, dtype: int64\n",
            "test\n",
            "A G    68\n",
            "G G    66\n",
            "A A    41\n",
            "Name: SNP_11, dtype: int64\n",
            "---------- SNP_12 ----------\n",
            "train\n",
            "A A    136\n",
            "G A     73\n",
            "G G     53\n",
            "Name: SNP_12, dtype: int64\n",
            "test\n",
            "A A    93\n",
            "G A    48\n",
            "G G    34\n",
            "Name: SNP_12, dtype: int64\n",
            "---------- SNP_13 ----------\n",
            "train\n",
            "G G    115\n",
            "A G     95\n",
            "A A     52\n",
            "Name: SNP_13, dtype: int64\n",
            "test\n",
            "G G    76\n",
            "A G    58\n",
            "A A    41\n",
            "Name: SNP_13, dtype: int64\n",
            "---------- SNP_14 ----------\n",
            "train\n",
            "A A    185\n",
            "C A     54\n",
            "C C     23\n",
            "Name: SNP_14, dtype: int64\n",
            "test\n",
            "A A    120\n",
            "C A     33\n",
            "C C     22\n",
            "Name: SNP_14, dtype: int64\n",
            "---------- SNP_15 ----------\n",
            "train\n",
            "A A    107\n",
            "G A    100\n",
            "G G     55\n",
            "Name: SNP_15, dtype: int64\n",
            "test\n",
            "G A    68\n",
            "A A    68\n",
            "G G    39\n",
            "Name: SNP_15, dtype: int64\n",
            "---------- class ----------\n",
            "train\n",
            "B    114\n",
            "C     79\n",
            "A     69\n",
            "Name: class, dtype: int64\n",
            "test\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'class'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-528b995716c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'class'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocess:\n",
        "    train_x = None\n",
        "    test_x = None\n",
        "    test_x = None\n",
        "    snp_cols = {\"SNP_\"+str(i).zfill(2):None for i in range(1,16)}\n",
        "\n",
        "    def __init__(self, train, test):\n",
        "        train_df = train\n",
        "        test_df = test\n",
        "\n",
        "        self.train_x = train_df.drop(columns=[\"id\",\"father\",\"mother\",\"gender\"])\n",
        "        self.test_x = test_df.drop(columns=[\"id\",\"father\",\"mother\",\"gender\"])\n",
        "\n",
        "        self.train_y = self.train_x[\"class\"]\n",
        "        self.train_x = self.train_x.drop(columns=[\"class\"])\n",
        "\n",
        "        # encoder_dict = self.do_label_encoding(self.train_x,self.snp_cols)\n",
        "        # self.test_x = self.labeling(self.test_x,encoder_dict)\n",
        "\n",
        "    def do_label_encoding(self,df,encoder_dict):\n",
        "        for col in encoder_dict:\n",
        "            le=LabelEncoder()\n",
        "            le.fit(df[col])\n",
        "            \n",
        "            encoder_dict[col]=le\n",
        "            df[col] = list(le.transform(df[col]))\n",
        "\n",
        "        return df, encoder_dict\n",
        "\n",
        "    def labeling(self,df,encoder_dict):\n",
        "        for key,encoder in encoder_dict.items():\n",
        "            df[key] = encoder.transform(df[key])\n",
        "        return df\n",
        "\n",
        "    def nominal_onehot(self,df,cols):\n",
        "        # make nominal onehot\n",
        "        for col in cols:\n",
        "            # dummy\n",
        "            dummy_df = pd.get_dummies(df[col])\n",
        "            # delete origin col\n",
        "            df = df.drop([col],axis=1)\n",
        "            # change col name type {origin col name}:dummy:{value}\n",
        "            dummy_df.columns = [col+\":dummy:\"+str(val) for val in dummy_df.columns]\n",
        "            # concat \n",
        "            df = pd.concat([df,dummy_df],axis=1)\n",
        "        return df\n",
        "    def split_alpha(self,df,cols):\n",
        "        '''\n",
        "        cols 컬럼들의 알파벳을 두개로 쪼갠다.\n",
        "        '''\n",
        "        for col in cols:\n",
        "            df[col+\"_01\"] = df[col].str[0]\n",
        "            df[col+\"_02\"] = df[col].str[2]\n",
        "        \n",
        "            df = df.drop(columns=[col])\n",
        "        \n",
        "        return df\n",
        "\n",
        "    def add_order(self,df):\n",
        "        '''\n",
        "        순서를 넣는다\n",
        "        '''\n",
        "        size = len(df)\n",
        "        order_df = pd.DataFrame({\"order\":[i for i in range(size)]})\n",
        "        \n",
        "        return pd.concat([order_df,df],axis=1)\n",
        "\n",
        "    def same_col(self,df):\n",
        "        for col in self.snp_cols:\n",
        "            df[col+\"_is_same\"] = np.array(df[col].str[0]==df[col].str[2],dtype=np.int64)\n",
        "        return df"
      ],
      "metadata": {
        "id": "wEqyYQ7oLhID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel:\n",
        "    train_x = None\n",
        "    train_y = None\n",
        "    test_x = None\n",
        "    \n",
        "    model = None\n",
        "    col_size = None\n",
        "    sample_submission = pd.read_csv(f\"{data_folder}/sample_submission.csv\")\n",
        "\n",
        "    def __init__(self,train_x,train_y,test_x):\n",
        "        self.train_x = train_x\n",
        "        self.train_y = train_y\n",
        "        self.test_x = test_x\n",
        "        \n",
        "        self.col_size = len(self.train_x.columns)\n",
        "\n",
        "    def train(self,model_name=None, n_splits=2, n_estimator=3000, early_stopping_rounds=300,\n",
        "              categorical_feature=[], random_state=42, verbose=1, test_size=0.3,):\n",
        "        \n",
        "        split_train_x, split_val_x, split_train_y, split_val_y = train_test_split(self.train_x, self.train_y, test_size=test_size, shuffle=True, random_state=random_state)\n",
        "        \n",
        "        if model_name == \"CatBoostClassifier\":\n",
        "            self.model = CatBoostClassifier(n_estimators=n_estimator, \n",
        "                                            random_state=random_state,\n",
        "                                            eval_metric=\"TotalF1\",\n",
        "                                            cat_features=categorical_feature\n",
        "                                            )\n",
        "\n",
        "            self.model.fit(split_train_x,split_train_y,\n",
        "                            eval_set=[(split_val_x,split_val_y)],\n",
        "                            early_stopping_rounds=early_stopping_rounds,\n",
        "                            verbose=verbose,\n",
        "                            )\n",
        "            \n",
        "        elif model_name ==\"LGBMClassifier\":\n",
        "            self.model = LGBMClassifier(n_estimators=n_estimator, \n",
        "                                        random_state=random_state,\n",
        "                                        )\n",
        "            self.model.fit(split_train_x,split_train_y,\n",
        "                            eval_set=[(split_val_x,split_val_y)],        \n",
        "                            early_stopping_rounds=early_stopping_rounds,\n",
        "                            verbose=verbose,\n",
        "                            categorical_feature=categorical_feature,\n",
        "                            )\n",
        "        elif model_name==\"XGBClassifier\":\n",
        "            self.model = XGBClassifier(n_estimators=n_estimator, \n",
        "                                  random_state=random_state)\n",
        "            self.model.fit(split_train_x,split_train_y,\n",
        "                      eval_set=[(split_val_x,split_val_y)], \n",
        "                      early_stopping_rounds=early_stopping_rounds,\n",
        "                      verbose=verbose)\n",
        "\n",
        "    def train_dnn(self,dropout=0.2,activefunc=\"relu\",epoch=2000,batch_size=40,patience=200,validation_split=0.2,verbose=1):\n",
        "        # ---------------모델 구조 생성---------------\n",
        "        self.model = tf.keras.Sequential()  \n",
        "\n",
        "        self.model.add(layers.Dense(60, input_shape=(self.col_size,)))  \n",
        "        self.model.add(layers.Activation(activefunc))  \n",
        "        self.model.add(layers.Dropout(dropout))        \n",
        "\n",
        "        self.model.add(layers.Dense(30))\n",
        "        self.model.add(layers.Activation(activefunc))  \n",
        "        self.model.add(layers.Dropout(dropout))    \n",
        "\n",
        "        self.model.add(layers.Dense(3))\n",
        "        self.model.add(layers.Activation('softmax')) \n",
        "        \n",
        "        # ---------------모델 구축하기---------------\n",
        "        self.model.compile(\n",
        "            loss='categorical_crossentropy',  #다중 교차엔트로피\n",
        "            optimizer=\"adam\",   #최적화 기법 중 하나\n",
        "            metrics=['accuracy'])  #정확도 측정\n",
        "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
        "        # ---------------모델 학습---------------\n",
        "        self.hist = self.model.fit(self.train_x, self.train_y, batch_size=batch_size, epochs=epoch, \n",
        "                                   validation_split=validation_split, verbose=verbose, callbacks = [callback])\n",
        "        \n",
        "    def predict(self):\n",
        "        self.sample_submission[\"class\"] = self.model.predict(self.test_x)\n",
        "        return self.sample_submission\n",
        "    \n",
        "    def predict_proba(self):\n",
        "        return self.model.predict_proba(self.test_x)\n",
        "\n",
        "    def predict_dnn(self):\n",
        "        def to_alpha(a):\n",
        "            if a==0:\n",
        "                return \"A\"\n",
        "            elif a==1:\n",
        "                return \"B\"\n",
        "            elif a==2:\n",
        "                return \"C\"\n",
        "\n",
        "        self.sample_submission[\"class\"] = np.argmax(self.model.predict(self.test_x),axis=1)\n",
        "        self.sample_submission[\"class\"] = self.sample_submission[\"class\"].apply(to_alpha)\n",
        "\n",
        "        return self.sample_submission\n",
        "    def see_feature_importance(self,model,train_x,test_x):\n",
        "        '''\n",
        "        input : model과 model을 학습한 train_x\n",
        "        output : 선택한 중요도 이상의 columns들을 가진 train_x, test_x로 데이터 재세팅\n",
        "        '''\n",
        "        pd.set_option('display.max_rows', None)\n",
        "        ft_importance_values = model.feature_importances_\n",
        "        ft_series = pd.Series(ft_importance_values, index = train_x.columns)\n",
        "        df_desc = pd.DataFrame(ft_series.sort_values(ascending=False)).reset_index()\n",
        "        display(df_desc)\n",
        "        \n",
        "        # [그래프 그리기]\n",
        "        df = pd.DataFrame(ft_series.sort_values(ascending=True)).reset_index()\n",
        "        fig = plt.figure(figsize=(30,20))\n",
        "        plt.barh(df[\"index\"],df[0])\n",
        "        \n",
        "        # 값 그래프 옆에 보이기\n",
        "        for i,v in enumerate(df[0]):\n",
        "            plt.text(v,i,str(round(v,6)))\n",
        "        plt.show()\n",
        "\n",
        "        cut = float(input(\"몇 이상부터 넣을지?\"))\n",
        "\n",
        "        df_cutted = df_desc.loc[df_desc[0]>=cut]\n",
        "        display(df_cutted)\n",
        "        df_cutted_list = list(df_cutted[\"index\"])\n",
        "\n",
        "        train_x_copy = train_x.copy()\n",
        "        test_x_copy = test_x.copy()\n",
        "\n",
        "        for col in train_x.columns:\n",
        "            if col not in df_cutted_list:\n",
        "                train_x_copy = train_x_copy.drop([col],axis=1)\n",
        "                test_x_copy = test_x_copy.drop([col],axis=1)\n",
        "\n",
        "        return train_x_copy,test_x_copy\n",
        "\n",
        "    def train_dnn_v2(self,dropout=0.2,activefunc=\"relu\",epoch=2000,batch_size=40,patience=200,validation_split=0.2,verbose=1):\n",
        "        # ---------------모델 구조 생성---------------\n",
        "        self.model = tf.keras.Sequential()  \n",
        "\n",
        "        self.model.add(layers.Dense(120, input_shape=(self.col_size,)))  \n",
        "        self.model.add(layers.Activation(activefunc))  \n",
        "        self.model.add(layers.Dropout(dropout))        \n",
        "\n",
        "        self.model.add(layers.Dense(60))       \n",
        "        self.model.add(layers.Activation(activefunc))\n",
        "        self.model.add(layers.Dropout(dropout))\n",
        "\n",
        "        self.model.add(layers.Dense(30))       \n",
        "        self.model.add(layers.Activation(activefunc))\n",
        "        self.model.add(layers.Dropout(dropout))\n",
        "\n",
        "        self.model.add(layers.Dense(3))\n",
        "        self.model.add(layers.Activation('softmax')) \n",
        "        \n",
        "        # ---------------모델 구축하기---------------\n",
        "        self.model.compile(\n",
        "            loss='categorical_crossentropy',  #다중 교차엔트로피\n",
        "            optimizer=\"rmsprop\",   #최적화 기법 중 하나\n",
        "            metrics=[\"accuracy\",tensorflow_addons.metrics.F1Score(num_classes=3, average='macro')])  #정확도 측정\n",
        "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_f1_score', patience=patience)\n",
        "        # ---------------모델 학습---------------\n",
        "        self.hist = self.model.fit(self.train_x, self.train_y, batch_size=batch_size, epochs=epoch, \n",
        "                                   validation_split=validation_split, verbose=verbose, callbacks = [callback])"
      ],
      "metadata": {
        "id": "j521-7m1PgO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModelCV:\n",
        "    train_x = None\n",
        "    train_y = None\n",
        "    test_x = None\n",
        "    \n",
        "    model_type = None     \n",
        "    model = None\n",
        "    categorical_cols = None\n",
        "    sample_submission = pd.read_csv(f\"{data_folder}/sample_submission.csv\")\n",
        "\n",
        "    def __init__(self,train_x,train_y,test_x):\n",
        "        self.train_x = train_x\n",
        "        self.train_y = train_y\n",
        "        self.test_x = test_x\n",
        "        \n",
        "    def train(self,model_name=None, n_estimator=3000, early_stopping_rounds=300,\n",
        "              categorical_feature=[], random_state=42, verbose=1, test_size=0.3,):\n",
        "        \n",
        "        cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "        data_args = (train_x,)\n",
        "\n",
        "        score = 0\n",
        "        for i,(tri, vai) in enumerate(cv.split(*data_args)):\n",
        "            print(\"=\"*30,i,\"=\"*30)\n",
        "            \n",
        "            if model_name == \"CatBoostClassifier\":\n",
        "                model = CatBoostClassifier(n_estimators=n_estimator, \n",
        "                                                random_state=random_state,\n",
        "                                                eval_metric=\"TotalF1\",\n",
        "                                                cat_features=categorical_feature\n",
        "                                                )\n",
        "\n",
        "                model.fit(train_x.iloc[tri],train_y.iloc[tri],\n",
        "                               eval_set=[(train_x.iloc[vai],train_y.iloc[vai])],\n",
        "                               early_stopping_rounds=early_stopping_rounds,\n",
        "                               verbose=verbose,\n",
        "                               )\n",
        "            elif model_name ==\"LGBMClassifier\":\n",
        "                self.model = LGBMClassifier(n_estimators=n_estimator, \n",
        "                                            random_state=random_state)\n",
        "                self.model.fit(train_x.iloc[tri],train_y.iloc[tri],\n",
        "                               eval_set=[(train_x.iloc[vai],train_y.iloc[vai])],        \n",
        "                               early_stopping_rounds=early_stopping_rounds,\n",
        "                               eval_metric=\"F1\",\n",
        "                               verbose=verbose,\n",
        "                               categorical_feature=categorical_feature,\n",
        "                               )\n",
        "                \n",
        "            score += model.get_best_score()[\"validation\"][\"TotalF1\"]\n",
        "            \n",
        "        score = score/n_splits\n",
        "        \n",
        "        return score\n",
        "\n",
        "    def predict(self):\n",
        "        self.sample_submission[\"class\"] = self.model.predict(self.test_x)\n",
        "        return self.sample_submission"
      ],
      "metadata": {
        "id": "YKKPaMrOzq6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "version = 8\n",
        "\n",
        "if version==1:\n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "\n",
        "    params = {\"model_name\" : \"CatBoostClassifier\",\n",
        "              \"n_estimator\": 3000, # epoch\n",
        "              \"early_stopping_rounds\" : 200, \n",
        "              \"categorical_feature\": list(preprocessor.snp_cols.keys()),\n",
        "              \"test_size\":0.3,\n",
        "    }\n",
        "\n",
        "    my_model = MyModel(train_x,train_y,test_x)\n",
        "    my_model.train(**params)\n",
        "    my_sub = my_model.predict()\n",
        "elif version==2:\n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "\n",
        "    params = {\"model_name\" : \"LGBMClassifier\",\n",
        "              \"n_estimator\": 3000, # epoch\n",
        "              \"early_stopping_rounds\" : 200, \n",
        "              \"categorical_feature\": list(preprocessor.snp_cols.keys()),\n",
        "              \"test_size\":0.3,\n",
        "    }\n",
        "    my_model = MyModel(train_x,train_y,test_x)\n",
        "    my_model.train(**params)\n",
        "    my_sub = my_model.predict()\n",
        "elif version==3:\n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "\n",
        "    params = {\"model_name\" : \"XGBClassifier\",\n",
        "              \"n_estimator\": 3000, # epoch\n",
        "              \"early_stopping_rounds\" : 200, \n",
        "              \"categorical_feature\": list(preprocessor.snp_cols.keys()),\n",
        "              \"test_size\":0.3,              \n",
        "    }\n",
        "    my_model = MyModel(train_x,train_y,test_x)\n",
        "    my_model.train(**params)\n",
        "    my_sub = my_model.predict()\n",
        "elif version==4: #11.csv\n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "    train_x = preprocessor.nominal_onehot(train_x,list(preprocessor.snp_cols.keys())+[\"trait\"])\n",
        "    test_x = preprocessor.nominal_onehot(test_x,list(preprocessor.snp_cols.keys())+[\"trait\"])\n",
        "    train_y = preprocessor.nominal_onehot(pd.DataFrame(preprocessor.train_y), [\"class\"])\n",
        "\n",
        "    my_model = MyModel(train_x,train_y,test_x)\n",
        "    params = {\"dropout\":0.2,\n",
        "              \"activefunc\":\"relu\",\n",
        "              \"epoch\":3000,\n",
        "              \"batch_size\":20,\n",
        "              \"patience\":300,\n",
        "              \"validation_split\":0.2\n",
        "              }\n",
        "    my_model.train_dnn(**params)\n",
        "    my_sub = my_model.predict_dnn()\n",
        "elif version==5:\n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "\n",
        "    \n",
        "    params = {\"model_name\" : \"CatBoostClassifier\",\n",
        "              \"n_estimator\": 3000, # epoch\n",
        "              \"early_stopping_rounds\" : 200, \n",
        "              \"categorical_feature\": list(preprocessor.snp_cols.keys()),\n",
        "              \"test_size\":0.3,\n",
        "    }\n",
        "    cat_model = MyModel(train_x,train_y,test_x)\n",
        "    cat_model.train(**params)\n",
        "    prob_array = np.array(cat_model.predict_proba())\n",
        "\n",
        "    params = {\"model_name\" : \"XGBClassifier\",\n",
        "              \"n_estimator\": 3000, # epoch\n",
        "              \"early_stopping_rounds\" : 200, \n",
        "              \"categorical_feature\": list(preprocessor.snp_cols.keys()),\n",
        "              \"test_size\":0.3,              \n",
        "    }\n",
        "    xgb_model = MyModel(train_x,train_y,test_x)\n",
        "    xgb_model.train(**params)\n",
        "    prob_array += np.array(xgb_model.predict_proba())\n",
        "\n",
        "    params = {\"model_name\" : \"LGBMClassifier\",\n",
        "              \"n_estimator\": 3000, # epoch\n",
        "              \"early_stopping_rounds\" : 200, \n",
        "              \"categorical_feature\": list(preprocessor.snp_cols.keys()),\n",
        "              \"test_size\":0.3,\n",
        "    }\n",
        "    lgbm_model = MyModel(train_x,train_y,test_x)\n",
        "    lgbm_model.train(**params)\n",
        "    prob_array += np.array(lgbm_model.predict_proba())\n",
        "\n",
        "    def to_alpha(a):\n",
        "        if a==0:\n",
        "            return \"A\"\n",
        "        elif a==1:\n",
        "            return \"B\"\n",
        "        elif a==2:\n",
        "            return \"C\"\n",
        "    sample_submission[\"class\"] = np.argmax(prob_array,axis=1)\n",
        "    sample_submission[\"class\"] = sample_submission[\"class\"].apply(to_alpha)\n",
        "    my_sub = sample_submission\n",
        "elif version==6: # 12.csv\n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "\n",
        "    train_x,encoder_dict = preprocessor.do_label_encoding(train_x,preprocessor.snp_cols)\n",
        "    test_x = preprocessor.labeling(test_x,encoder_dict)\n",
        "\n",
        "    train_x = preprocessor.nominal_onehot(train_x,list(preprocessor.snp_cols.keys())+[\"trait\"])\n",
        "    test_x = preprocessor.nominal_onehot(test_x,list(preprocessor.snp_cols.keys())+[\"trait\"])\n",
        "    train_y = preprocessor.nominal_onehot(pd.DataFrame(preprocessor.train_y), [\"class\"])\n",
        "\n",
        "    my_model = MyModel(train_x,train_y,test_x)\n",
        "    params = {\"dropout\":0.2,\n",
        "              \"activefunc\":\"relu\",\n",
        "              \"epoch\":3000,\n",
        "              \"batch_size\":20,\n",
        "              \"patience\":300,\n",
        "              \"validation_split\":0.2\n",
        "              }\n",
        "    my_model.train_dnn(**params)\n",
        "    my_sub = my_model.predict_dnn() \n",
        "elif version==7: \n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "    my_model = MyModel(train_x,train_y,test_x)\n",
        "    train_y_onehot = preprocessor.nominal_onehot(pd.DataFrame(preprocessor.train_y), [\"class\"])\n",
        "    params = {\"model_name\" : \"CatBoostClassifier\",\n",
        "              \"n_estimator\": 3000, # epoch\n",
        "              \"early_stopping_rounds\" : 200, \n",
        "              \"categorical_feature\": list(preprocessor.snp_cols.keys()),\n",
        "              \"test_size\":0.3,\n",
        "    }\n",
        "    my_model.train(**params)\n",
        "    pd.set_option('display.max_rows', None)\n",
        "\n",
        "    train_x_select, test_x_select = my_model.see_feature_importance(my_model.model,train_x,test_x)\n",
        "\n",
        "    train_x_select = preprocessor.nominal_onehot(train_x_select,list(train_x_select.columns))\n",
        "    test_x_select = preprocessor.nominal_onehot(test_x_select,list(test_x_select.columns))\n",
        "\n",
        "    dnn_model = MyModel(train_x_select,train_y_onehot,test_x_select)\n",
        "    params = {\"dropout\":0.2,\n",
        "              \"activefunc\":\"relu\",\n",
        "              \"epoch\":3000,\n",
        "              \"batch_size\":20,\n",
        "              \"patience\":200,\n",
        "              \"validation_split\":0.2\n",
        "              }\n",
        "    dnn_model.train_dnn(**params)\n",
        "    my_sub = dnn_model.predict_dnn()   \n",
        "elif version==8: #11.csv\n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "\n",
        "    train_x = preprocessor.split_alpha(train_x,preprocessor.snp_cols)\n",
        "    test_x = preprocessor.split_alpha(test_x,preprocessor.snp_cols)\n",
        "    \n",
        "    train_x = preprocessor.nominal_onehot(train_x,list(train_x.columns))\n",
        "    test_x = preprocessor.nominal_onehot(test_x,list(test_x.columns))\n",
        "    train_y = preprocessor.nominal_onehot(pd.DataFrame(preprocessor.train_y), [\"class\"])\n",
        "\n",
        "    my_model = MyModel(train_x,train_y,test_x)\n",
        "    params = {\"dropout\":0.2,\n",
        "              \"activefunc\":\"relu\",\n",
        "              \"epoch\":3000,\n",
        "              \"batch_size\":20,\n",
        "              \"patience\":300,\n",
        "              \"validation_split\":0.2,\n",
        "              \"verbose\":1,\n",
        "              }\n",
        "    my_model.train_dnn(**params)\n",
        "    my_sub = my_model.predict_dnn() \n",
        "elif version==9:\n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "\n",
        "    train_x = preprocessor.split_alpha(train_x,preprocessor.snp_cols)\n",
        "    test_x = preprocessor.split_alpha(test_x,preprocessor.snp_cols)\n",
        "    \n",
        "    label_encoder_dict = {col:None for col in list(train_x.columns)}\n",
        "    train_x,encoder_dict = preprocessor.do_label_encoding(train_x,label_encoder_dict)\n",
        "    test_x = preprocessor.labeling(test_x,encoder_dict)\n",
        "\n",
        "    params = {\"model_name\" : \"CatBoostClassifier\",\n",
        "              \"n_estimator\": 3000, # epoch\n",
        "              \"early_stopping_rounds\" : 200, \n",
        "              \"categorical_feature\": list(label_encoder_dict.keys()),\n",
        "              \"test_size\":0.3,\n",
        "              \"verbose\":1,\n",
        "    }\n",
        "\n",
        "    my_model = MyModel(train_x,train_y,test_x)\n",
        "    my_model.train(**params)\n",
        "    my_sub = my_model.predict()\n",
        "elif version==10:\n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "\n",
        "    train_x = preprocessor.split_alpha(train_x,preprocessor.snp_cols)\n",
        "    test_x = preprocessor.split_alpha(test_x,preprocessor.snp_cols)\n",
        "    \n",
        "    train_x = preprocessor.nominal_onehot(train_x,list(train_x.columns))\n",
        "    test_x = preprocessor.nominal_onehot(test_x,list(test_x.columns))\n",
        "    train_y = preprocessor.nominal_onehot(pd.DataFrame(preprocessor.train_y), [\"class\"])\n",
        "\n",
        "    train_x = preprocessor.add_order(train_x)\n",
        "    test_x = preprocessor.add_order(test_x)\n",
        "\n",
        "    my_model = MyModel(train_x,train_y,test_x)\n",
        "    params = {\"dropout\":0.2,\n",
        "              \"activefunc\":\"relu\",\n",
        "              \"epoch\":3000,\n",
        "              \"batch_size\":20,\n",
        "              \"patience\":300,\n",
        "              \"validation_split\":0.2,\n",
        "              \"verbose\":1,\n",
        "              }\n",
        "    my_model.train_dnn(**params)\n",
        "    my_sub = my_model.predict_dnn() \n",
        "elif version==11: \n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "\n",
        "    train_x = preprocessor.split_alpha(train_x,preprocessor.snp_cols)\n",
        "    test_x = preprocessor.split_alpha(test_x,preprocessor.snp_cols)\n",
        "    \n",
        "    train_x = preprocessor.nominal_onehot(train_x,list(train_x.columns))\n",
        "    test_x = preprocessor.nominal_onehot(test_x,list(test_x.columns))\n",
        "    train_y = preprocessor.nominal_onehot(pd.DataFrame(preprocessor.train_y), [\"class\"])\n",
        "\n",
        "    my_model = MyModel(train_x,train_y,test_x)\n",
        "    params = {\"dropout\":0.2,\n",
        "              \"activefunc\":\"relu\",\n",
        "              \"epoch\":6000,\n",
        "              \"batch_size\":10,\n",
        "              \"patience\":500,\n",
        "              \"validation_split\":0.15,\n",
        "              \"verbose\":1,\n",
        "              }\n",
        "    my_model.train_dnn(**params)\n",
        "    my_sub = my_model.predict_dnn() \n",
        "elif version==12: \n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "\n",
        "    train_x = preprocessor.same_col(train_x)\n",
        "    test_x = preprocessor.same_col(test_x)\n",
        "\n",
        "    train_x = preprocessor.split_alpha(train_x,preprocessor.snp_cols)\n",
        "    test_x = preprocessor.split_alpha(test_x,preprocessor.snp_cols)\n",
        "\n",
        "    onehot_cols = [train_x.columns[0]]+list(train_x.columns[16:])\n",
        "    train_x = preprocessor.nominal_onehot(train_x, onehot_cols)\n",
        "    test_x = preprocessor.nominal_onehot(test_x, onehot_cols)\n",
        "    train_y = preprocessor.nominal_onehot(pd.DataFrame(preprocessor.train_y), [\"class\"])\n",
        "    \n",
        "    \n",
        "    assert all(np.array(train_x.columns)==np.array(test_x.columns))\n",
        "\n",
        "    my_model = MyModel(train_x,train_y,test_x)\n",
        "    params = {\"dropout\":0.2,\n",
        "              \"activefunc\":\"relu\",\n",
        "              \"epoch\":3000,\n",
        "              \"batch_size\":20,\n",
        "              \"patience\":300,\n",
        "              \"validation_split\":0.2,\n",
        "              \"verbose\":1,\n",
        "              }\n",
        "    my_model.train_dnn(**params)\n",
        "    my_sub = my_model.predict_dnn() \n",
        "elif version==13: \n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "\n",
        "    train_x = preprocessor.same_col(train_x)\n",
        "    test_x = preprocessor.same_col(test_x)\n",
        "    \n",
        "    train_x = train_x.drop(columns=Preprocess.snp_cols.keys())\n",
        "    test_x = test_x.drop(columns=Preprocess.snp_cols.keys())\n",
        "\n",
        "    onehot_cols = [\"trait\"]\n",
        "    train_x = preprocessor.nominal_onehot(train_x, onehot_cols)\n",
        "    test_x = preprocessor.nominal_onehot(test_x, onehot_cols)\n",
        "    train_y = preprocessor.nominal_onehot(pd.DataFrame(preprocessor.train_y), [\"class\"])\n",
        "        \n",
        "    assert all(np.array(train_x.columns)==np.array(test_x.columns))\n",
        "\n",
        "    my_model = MyModel(train_x,train_y,test_x)\n",
        "    params = {\"dropout\":0.2,\n",
        "              \"activefunc\":\"relu\",\n",
        "              \"epoch\":3000,\n",
        "              \"batch_size\":20,\n",
        "              \"patience\":300,\n",
        "              \"validation_split\":0.2,\n",
        "              \"verbose\":1,\n",
        "              }\n",
        "    my_model.train_dnn(**params)\n",
        "    my_sub = my_model.predict_dnn() \n",
        "elif version==15: #11.csv\n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "\n",
        "    train_x = preprocessor.split_alpha(train_x,preprocessor.snp_cols)\n",
        "    test_x = preprocessor.split_alpha(test_x,preprocessor.snp_cols)\n",
        "    \n",
        "    train_x = preprocessor.nominal_onehot(train_x,list(train_x.columns))\n",
        "    test_x = preprocessor.nominal_onehot(test_x,list(test_x.columns))\n",
        "    train_y = preprocessor.nominal_onehot(pd.DataFrame(preprocessor.train_y), [\"class\"])\n",
        "\n",
        "    my_model = MyModel(train_x,train_y,test_x)\n",
        "    params = {\"dropout\":0.2,\n",
        "              \"activefunc\":\"relu\",\n",
        "              \"epoch\":3000,\n",
        "              \"batch_size\":20,\n",
        "              \"patience\":300,\n",
        "              \"validation_split\":0.2,\n",
        "              \"verbose\":1,\n",
        "              }\n",
        "    my_model.train_dnn(**params)\n",
        "    my_sub = my_model.predict_dnn() \n",
        "elif version==16:\n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "\n",
        "    train_x = preprocessor.split_alpha(train_x,preprocessor.snp_cols)\n",
        "    test_x = preprocessor.split_alpha(test_x,preprocessor.snp_cols)\n",
        "    \n",
        "    train_x = preprocessor.nominal_onehot(train_x,list(train_x.columns))\n",
        "    test_x = preprocessor.nominal_onehot(test_x,list(test_x.columns))\n",
        "    train_y = preprocessor.nominal_onehot(pd.DataFrame(preprocessor.train_y), [\"class\"])\n",
        "\n",
        "    my_model = MyModel(train_x,train_y,test_x)\n",
        "    params = {\"dropout\":0.2,\n",
        "              \"activefunc\":\"relu\",\n",
        "              \"epoch\":3000,\n",
        "              \"batch_size\":20,\n",
        "              \"patience\":300,\n",
        "              \"validation_split\":0.2,\n",
        "              \"verbose\":1,\n",
        "              }\n",
        "    my_model.train_dnn(**params)\n",
        "    my_sub = my_model.predict_dnn() \n",
        "elif version==17:\n",
        "    def run_PCA(X, num_components):\n",
        "        pca = sklearn.decomposition.PCA(n_components=num_components)\n",
        "        pca.fit(X)\n",
        "        pca_array = pca.transform(X)\n",
        "        return pca, pca_array\n",
        "\n",
        "    preprocessor = Preprocess(train,test)\n",
        "    train_x,train_y,test_x = preprocessor.train_x,preprocessor.train_y,preprocessor.test_x\n",
        "\n",
        "    train_x = preprocessor.split_alpha(train_x,preprocessor.snp_cols)\n",
        "    test_x = preprocessor.split_alpha(test_x,preprocessor.snp_cols)\n",
        "\n",
        "    label_encoder_dict = {col:None for col in list(train_x.columns)}\n",
        "    train_x,encoder_dict = preprocessor.do_label_encoding(train_x,label_encoder_dict)\n",
        "    test_x = preprocessor.labeling(test_x,encoder_dict)\n",
        "\n",
        "    # print(train_x,test_x)\n",
        "    pca, train_x_array = run_PCA(train_x,8)\n",
        "    test_x_array = pca.transform(test_x)\n",
        "\n",
        "    train_x = pd.DataFrame(train_x_array)\n",
        "    test_x = pd.DataFrame(test_x_array)\n",
        "    train_y = preprocessor.nominal_onehot(pd.DataFrame(preprocessor.train_y), [\"class\"])\n",
        "\n",
        "    my_model = MyModel(train_x,train_y,test_x)\n",
        "    params = {\"dropout\":0.2,\n",
        "            \"activefunc\":\"relu\",\n",
        "            \"epoch\":3000,\n",
        "            \"batch_size\":20,\n",
        "            \"patience\":300,\n",
        "            \"validation_split\":0.2,\n",
        "            \"verbose\":1,\n",
        "                }\n",
        "    my_model.train_dnn(**params)\n",
        "    my_sub = my_model.predict_dnn() "
      ],
      "metadata": {
        "id": "DlQIslxyc1Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ft_series = pd.Series(ft_importance_values, index = train_x.columns)\n",
        "df_desc = pd.DataFrame(ft_series.sort_values(ascending=False)).reset_index()\n",
        "display(df_desc)\n",
        "\n",
        "# [그래프 그리기]\n",
        "df = pd.DataFrame(ft_series.sort_values(ascending=True)).reset_index()\n",
        "fig = plt.figure(figsize=(30,20))\n",
        "plt.barh(df[\"index\"],df[0])\n",
        "\n",
        "# 값 그래프 옆에 보이기\n",
        "for i,v in enumerate(df[0]):\n",
        "    plt.text(v,i,str(round(v,6)))\n",
        "plt.show()\n",
        "\n",
        "cut = float(input(\"몇 이상부터 넣을지?\"))\n",
        "\n",
        "df_cutted = df_desc.loc[df_desc[0]>=cut]\n",
        "display(df_cutted)\n",
        "df_cutted_list = list(df_cutted[\"index\"])\n",
        "\n",
        "train_x_copy = train_x.copy()\n",
        "test_x_copy = test_x.copy()\n",
        "\n",
        "for col in train_x.columns:\n",
        "    if col not in df_cutted_list:\n",
        "        train_x_copy = train_x_copy.drop([col],axis=1)\n",
        "        test_x_copy = test_x_copy.drop([col],axis=1)"
      ],
      "metadata": {
        "id": "jcKYQ2zk95Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 제출용 (content에 dacon_submit_api넣어야한다 )\n",
        "!pip install dacon_submit_api-0.0.4-py3-none-any.whl\n",
        "from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "# 제출파일 만들기\n",
        "def get_file_name():\n",
        "    def returnNum(s):\n",
        "        return int(s[:-4])\n",
        "\n",
        "    files = os.listdir(path+\"/sub\")\n",
        "    try:\n",
        "        new_file_num = max(list(map(returnNum,files)))+1\n",
        "        file_name = str(new_file_num)+\".csv\"\n",
        "    except:\n",
        "        file_name = \"1.csv\"\n",
        "    return file_name \n",
        "    \n",
        "def submission():\n",
        "    file_name = get_file_name()\n",
        "    print(file_name)\n",
        "    my_sub.to_csv(path+\"/sub/\"+file_name,index=False)\n",
        "\n",
        "    # 제출\n",
        "    sub_memo = f\"version : {version}\" # !!!!!!메모!!!!!!\n",
        "    path_for_sub = path+\"/sub/\"+file_name\n",
        "    token = \"??\"\n",
        "    my_id = \"??\"\n",
        "    my_team = \"씩씩한오리너구리\"\n",
        "\n",
        "    result = dacon_submit_api.post_submission_file(\n",
        "        path_for_sub, \n",
        "        token, \n",
        "        my_id, \n",
        "        my_team, \n",
        "        sub_memo )\n",
        "    \n",
        "    return result\n",
        "\n",
        "submission()    "
      ],
      "metadata": {
        "id": "6CU6GweFXtl4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}